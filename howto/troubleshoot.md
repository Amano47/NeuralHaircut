# 4. Troubleshoot Guide

Most of the things written here should not have come up, if you followd my [Guide](/howto/), but here are some types of errors I encountered.

GL;HF

## ToC

4.1 [Conda Environment](#41-conda-environment)  
4.2 [Colmap](#42-colmap)  
4.3 [Masks checkpoints](#43-masks-a)  
4.4 [Masks python](#44-masks-b)  
4.5 [Pixie (initialization)](#45-pixie)  


## 4.1 Conda environment

You may have conflicts between packages when creating the conda environment with [neural_haircut.yaml](/neural_haircut.yaml).  

Change in [Line 165](../neural_haircut.yaml#L165)

```yaml
- notebook=6.5.3=py39h06a4308_0 #from this 
- notebook=6.5.* #to this
```


## 4.2 Colmap

Colmap is a optional step in the preprocessing step for custom data. But if there are not many images to extract features and to match these, then it is a rather difficult task to get usable results from colmap for the [preprocessing step](/preprocess_custom_data/readme.md#step-1-optional-run-colmap-sfm-to-obtain-cameras).  

If you have masks or silhouettes of your photos/frames, then you can use them in the automatic reconstructor of colmap with  
```bash
colmap automatic_reconstructor --workspace_path ./colmap/ --image_path ./image/ --mask_path ./masks/
```

```bash
|-- case_name			# run the command from here
	|-- video_frames
	|-- image			# all images
	|-- mask			# the masks created from the images
	|-- colmap
		|-- sparse		# this gets automatically generated by colmap
			|-- 0
				|-- image.bin     <--+
				|-- camera.bin    <--+-- get generated by automatic_reconstructor 
				|-- points3D.bin  <--+
	|-- ...				# rest of your preprocess files
	...

```

You can generate the masks with [Step 2.x]() (the one after Colmap)



## 4.3 Masks checkpoint

The mask generator is very straight forward.  
It uses [MODNet](/MODNet/) for silhouettes, so whole body masks and [CDGNet](/CDGNet/) for hair masks.  
The pretrained models are not inside the submodules, so you have to download them from the linked Google Drive.  

**! Be careful !**  
There are at least two different versions of the CDGNet file, which all are named the same `LIP_epoch_149.pth` only with slightly different sizes (255MB and 305MB).  
The smaller one, which is "outdated" and also gets referred in the Master and other Repositories, doesn't work properly and stops the python code with errors.  

+++++++++++++++++++++++++++++  
+**[this is the one, which works in Jan 2025](https://onedrive.live.com/?redeem=aHR0cHM6Ly8xZHJ2Lm1zL2YvcyFBaGZRbUVIelk1NFlhMmdHYXNsWG5NMklQQ2s%5FZT1waGs1bWU&id=189E63F34198D017%21107&cid=189E63F34198D017)**+  
+++++++++++++++++++++++++++++  

Put it into `/CDGNet/snapshots/` and the code should be fine.  



## 4.4 Masks python code

Another issue with the mask generator is, that it seems to have problems with the code itself in [line 159](https://github.com/Amano47/NeuralHaircut/blob/1dbdd07797458e6e0000bd3a02f3092d419d1756/preprocess_custom_data/calc_masks.py#L159).

To resolve it:  

```python
...
156     state_dict = model.state_dict().copy()
157     state_dict_old = torch.load(args.CDGNET_ckpt, map_location='cpu')
158
159-    for key, nkey in zip(state_dict_old.keys(), state_dict.keys()): # delete this line
159+    state_dict_keys = list(state_dict.keys()) 
160+    for key, nkey in zip(state_dict_old.keys(), state_dict_keys):
161         if key != nkey:
162             # remove the 'module.' in the 'key'
163             state_dict[key[7:]] = deepcopy(state_dict_old[key])
...
```

So that the counting state_dict doesn't get mutated.  
This is from [Issue #13](https://github.com/SamsungLabs/NeuralHaircut/issues/13)  



## 4.5 Pixie



## 4.6 MeshLab


## 4.7 OpenPose



## 4.8 fitted_cameras.pth